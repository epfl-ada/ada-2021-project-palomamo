{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morwald/ada_project/blob/main/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7txCTyrTM0qJ"
      },
      "source": [
        "# Female citations in UKs leading news papers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEzY5GJ5M0qO"
      },
      "source": [
        "This notebook serves as a first presentation of our project for milestone 2. It is structured and written in such  a way that we can directly continue on it for milestone 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucef3_UkM0qP"
      },
      "source": [
        "## Content\n",
        "1. [Setup](#setup)   \n",
        "    1.1 [Imports](#imports)  \n",
        "    1.2 [Data paths](#data_paths)   \n",
        "    1.3 [Utility functions](#utility_functions)   \n",
        "2. [Data preparation](#data_prep)    \n",
        "    2.1 [Columns and rows selection](#cols_rows_select)  \n",
        "    2.2 [News paper selection](#newspaper_select)           \n",
        "    2.3 [Filtering raw data](#filter_raw_data)   \n",
        "    2.4 [Merging speaker information](#merging_speakers)   \n",
        "3. [Data exploration and cleaning](#data_explore_clean)  \n",
        "    3.1 [Import prepared data](#import_prep_data)   \n",
        "    3.2 [Set index](#set_index)    \n",
        "    3.3 [Save cleaned data frame as pickle](#save_pickle)   \n",
        "4. [Research questions](#research_question)     \n",
        "    4.1 [Load pickled dataframes](#load_pickle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owgTJarZM0qP"
      },
      "source": [
        "## 1. Setup\n",
        "<a id=\"setup\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yqsvZuAM0qQ"
      },
      "source": [
        "### 1.1 Imports\n",
        "<a id=\"imports\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFoAWQprM0qQ"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import bz2\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKWfSxjgM0qR"
      },
      "source": [
        "### 1.2 Data paths\n",
        "<a id=\"Data paths\"></a>\n",
        "\n",
        "**Important**: The raw and prepared data are stored locally in the root folder _raw_data_ and _data_. To execute section [Data preperation](#data_prep) the raw data is needed. This section has to be executed only once.\n",
        "\n",
        "You can download the raw data here (EPFL google account required): [Quotebank](), [Speakers]()\n",
        "\n",
        "The cleaned data can be found using this link:\n",
        "[Cleaned data]()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qefk9v2tSmnT"
      },
      "source": [
        "We mount the drive and go to the right directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYbQA-9aNUeC",
        "outputId": "dfffddef-d411-4314-f1c7-ab62a8af1a6f"
      },
      "source": [
        "# Import epfl google drive!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWm5eUlINbjX",
        "outputId": "eb4b6a73-ea4c-4b15-d3f4-52f0aa49c2e8"
      },
      "source": [
        "%cd /content/drive/Shareddrives/ADA-project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/Shareddrives/ADA-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ADHNIxSvDl"
      },
      "source": [
        "We install an older version of pandas in order to be able to use the 'chunksize' feature in colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24i5C-GlRwGW",
        "outputId": "adf027f1-7970-4f55-b12f-8f75feeb5979"
      },
      "source": [
        "!pip install pandas==1.0.5\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas==1.0.5 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.5) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SYhsZXWR2OA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0EyOzun0R8Bj",
        "outputId": "4f35c0ae-1188-4588-dd12-f268c7a8f2ab"
      },
      "source": [
        "pd.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.5'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-ctBnWnS7V9"
      },
      "source": [
        "We get the link to the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcGKsptEM0qS"
      },
      "source": [
        "# Paths of the files\n",
        "RAW_QUOTES_2020_PATH = 'Quotebank/quotes-2020.json.bz2' \n",
        "QUOTES_2020_PATH = 'Filtered data/quotes-2020-gb.json.bz2' \n",
        "\n",
        "RAW_QUOTES_2019_PATH = 'Quotebank/quotes-2019.json.bz2' \n",
        "QUOTES_2019_PATH = 'Filtered data/quotes-2019-gb.json.bz2' \n",
        "\n",
        "RAW_QUOTES_2018_PATH = 'Quotebank/quotes-2018.json.bz2' \n",
        "QUOTES_2018_PATH = 'Filtered data/quotes-2018-gb.json.bz2' \n",
        "\n",
        "RAW_QUOTES_2017_PATH = 'Quotebank/quotes-2017.json.bz2' \n",
        "QUOTES_2017_PATH = 'Filtered data/quotes-2017-gb.json.bz2' \n",
        "\n",
        "RAW_QUOTES_2016_PATH = 'Quotebank/quotes-2016.json.bz2' \n",
        "QUOTES_2016_PATH = 'Filtered data/quotes-2016-gb.json.bz2' \n",
        "\n",
        "RAW_QUOTES_2015_PATH = 'Quotebank/quotes-2015.json.bz2' \n",
        "QUOTES_2015_PATH = 'Filtered data/quotes-2015-gb.json.bz2'"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KymkAGpdM0qT"
      },
      "source": [
        "## 1.3 Utility functions\n",
        "<a id=\"utility_functions\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-3lMRqhSf4Q"
      },
      "source": [
        "This version of the function is for the older version of pandas (1.0.5) in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAN-njz8SJ2z"
      },
      "source": [
        "def load_mini_version_of_data_old_pandas(path_to_file, chunksize, nb_chunks):\n",
        "    \"\"\"\n",
        "    Returns a mini dataframe from of a bz2 compressed json file.\n",
        "    :path_to_file: file path as string\n",
        "    :chunksize: size to iterate\n",
        "    :nb_chunks: how many chunks\n",
        "    :return: pandas.DataFrame with chunksize*nb_chunks of rows\n",
        "    \"\"\"\n",
        "        \n",
        "    curr_chunk = 0\n",
        "    chunk_list = []\n",
        "    \n",
        "    for chunk in pd.read_json(path_to_file, lines=True, compression='bz2', chunksize=chunksize):\n",
        "      if curr_chunk == nb_chunks:\n",
        "          break\n",
        "            \n",
        "      curr_chunk = curr_chunk + 1\n",
        "      chunk_list.append(chunk)\n",
        "    \n",
        "    df = pd.concat(chunk_list)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3X94ETfM0qU"
      },
      "source": [
        "## 2. Data preparation\n",
        "<a id=\"data_prep\"></a>\n",
        "\n",
        "The quotebank dataset is too large to directly access it with a dataframe. This section provides all the steps to filter the data we need for our analysis. The filtering and preperation is done based on our research question. Please check the README for details. Further explanations are given under [Research question](#research_question).\n",
        "\n",
        "The data preperation can be done on a per year basis of the Quotebank data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aBizKy0M0qV"
      },
      "source": [
        "### 2.1 Column and row selection\n",
        "<a id=\"cols_rows_select\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "DDiGK7IoM0qV",
        "outputId": "2fd573e4-abc9-4b49-c3f7-72c995b25ef9"
      },
      "source": [
        "# A quick look at a small subset of the data of the selected year\n",
        "year_sample_df = load_mini_version_of_data_old_pandas(RAW_QUOTES_2020_PATH, 10000, 10)\n",
        "year_sample_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>qids</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-28-000082</td>\n",
              "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-01-28 08:04:05</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.7272], [Prime Minister Netanyahu, 0....</td>\n",
              "      <td>[http://israelnationalnews.com/News/News.aspx/...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-16-000088</td>\n",
              "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
              "      <td>Sue Myrick</td>\n",
              "      <td>[Q367796]</td>\n",
              "      <td>2020-01-16 12:00:13</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
              "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-10-000142</td>\n",
              "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-10 23:45:54</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.8926], [Prakash Rai, 0.1074]]</td>\n",
              "      <td>[https://indianexpress.com/article/business/ec...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-15-000053</td>\n",
              "      <td>... [ I ] f it gets to the floor,</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-15 14:12:51</td>\n",
              "      <td>2</td>\n",
              "      <td>[[None, 0.581], [Andy Harris, 0.4191]]</td>\n",
              "      <td>[https://patriotpost.us/opinion/68622-trump-bu...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-24-000168</td>\n",
              "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
              "      <td>Meghan King Edmonds</td>\n",
              "      <td>[Q20684375]</td>\n",
              "      <td>2020-01-24 20:37:09</td>\n",
              "      <td>4</td>\n",
              "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
              "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             quoteID  ... phase\n",
              "0  2020-01-28-000082  ...     E\n",
              "1  2020-01-16-000088  ...     E\n",
              "2  2020-02-10-000142  ...     E\n",
              "3  2020-02-15-000053  ...     E\n",
              "4  2020-01-24-000168  ...     E\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBzK83L9M0qW",
        "scrolled": true,
        "outputId": "7f2f2d1d-08e4-4caa-e0ea-cc0af11931d5"
      },
      "source": [
        "# How many quotations don't have an assigned speaker?\n",
        "sum(year_sample_df['speaker'] == 'None')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34316"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH6Hbvv_M0qW"
      },
      "source": [
        "The cell above shows that there around 1/3 of the quotations are 'None' speakers. As we want to make a gender based study will will not need these rows. This eliminitation will drasticly reduce the size of the data we have to analyse.\n",
        "\n",
        "Furthermore the colums which aren't of interest for our study are:\\\n",
        "**phase**: we don't care\\\n",
        "**probas**: as we will select the the speaker with highest probablity (note that 'None' speakers are already neglected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_WR9hCM0qX"
      },
      "source": [
        "### 2.2 Newspaper selection\n",
        "<a id=\"nespaper_select\"></a>\n",
        "In first analysis we will pick quotations of 3 of the top 12 UKs newspapers with the most reach both in prints and digital reach. See [this]() statistic for further details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "MqiT955RM0qX",
        "outputId": "2a5ca0be-6007-43b4-c7ce-fb76a6e4e75a"
      },
      "source": [
        "# List of selected newspapers and their urls\n",
        "newspapers_list = [['The Sun', 'thesun.co.uk'], \n",
        "              ['The Guardian', 'theguardian.com'],\n",
        "              ['The Times', 'thetimes.co.uk']]\n",
        "\n",
        "# Dataframe\n",
        "newspapers_df = pd.DataFrame(newspapers_list, columns = ['name', 'website_url'])\n",
        "newspapers_df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>website_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Sun</td>\n",
              "      <td>thesun.co.uk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Guardian</td>\n",
              "      <td>theguardian.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Times</td>\n",
              "      <td>thetimes.co.uk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name      website_url\n",
              "0       The Sun     thesun.co.uk\n",
              "1  The Guardian  theguardian.com\n",
              "2     The Times   thetimes.co.uk"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PSbHGGtM0qX"
      },
      "source": [
        "### 2.3 Filtering raw data\n",
        "<a id=\"filter_raw_data\"></a>\n",
        "\n",
        "Fowolling the reasoning above we can extract the infos needed from the compressed file of a year of quotations. Let's create a helper function to check the primary urls of a quotation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "902eh0g-cu78"
      },
      "source": [
        "def filter_data(path_in, path_out):\n",
        "  # Loop through all instances of json file and extract the desired rows\n",
        "  # Save the File in the data directory\n",
        "  with bz2.open(path_in, 'rb') as s_file:\n",
        "      with bz2.open(path_out, 'wb') as d_file:\n",
        "          for instance in s_file:\n",
        "              instance = json.loads(instance) # loading a sample\n",
        "              if instance['speaker'] == 'None':\n",
        "                  continue\n",
        "              urls = instance['urls'] # extracting list of links\n",
        "              newspapers = []\n",
        "             # website_urls = get_website_names(urls)\n",
        "              for url in urls:\n",
        "                  for name, website_url in zip(newspapers_df['name'],newspapers_df['website_url']):\n",
        "                      if website_url in url:\n",
        "                          newspapers.append(name)\n",
        "                          instance['newspapers'] = newspapers # updating the sample with domain name\n",
        "              # we remove unnecessary columns\n",
        "              instance.pop('probas')\n",
        "              instance.pop('phase')\n",
        "              # if there is a newspaper that we want to keep we write the instance to the output file\n",
        "              if newspapers: \n",
        "                d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file\n",
        "                "
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPJda6mObZja"
      },
      "source": [
        "filter_data(RAW_QUOTES_2020_PATH,QUOTES_2020_PATH)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "APW1C9ivsu-G",
        "outputId": "b14e2e98-e2cf-46c3-a163-2a8f81cccb3e"
      },
      "source": [
        "#we check that the new file contains the right data\n",
        "filtered_sample_df = load_mini_version_of_data_old_pandas(QUOTES_2020_PATH, 10000, 10)\n",
        "filtered_sample_df.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>qids</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>urls</th>\n",
              "      <th>newspapers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-31-008580</td>\n",
              "      <td>As you reach or have reached the apex of your ...</td>\n",
              "      <td>Keyon Dooling</td>\n",
              "      <td>[Q304349]</td>\n",
              "      <td>2020-01-31 19:07:55</td>\n",
              "      <td>1</td>\n",
              "      <td>[https://www.theguardian.com/sport/2020/jan/31...</td>\n",
              "      <td>[The Guardian]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-20-006469</td>\n",
              "      <td>At the same time we want to remain friends wit...</td>\n",
              "      <td>Tim Martin</td>\n",
              "      <td>[Q20670776, Q20713880, Q7803899, Q7803900]</td>\n",
              "      <td>2020-01-20 09:08:24</td>\n",
              "      <td>4</td>\n",
              "      <td>[https://www.dailystar.co.uk/real-life/wethers...</td>\n",
              "      <td>[The Sun]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-04-03-006933</td>\n",
              "      <td>Been home-schooling a 6-year-old and 8-year-ol...</td>\n",
              "      <td>Shonda Rhimes</td>\n",
              "      <td>[Q242329]</td>\n",
              "      <td>2020-04-03 16:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>[http://www.thetimes.co.uk/edition/magazine/ca...</td>\n",
              "      <td>[The Times]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-04-15-018814</td>\n",
              "      <td>I am now in agreement that we should move forw...</td>\n",
              "      <td>David Boies</td>\n",
              "      <td>[Q5231515]</td>\n",
              "      <td>2020-04-15 15:46:38</td>\n",
              "      <td>1</td>\n",
              "      <td>[https://www.thesun.co.uk/news/11403669/jeffre...</td>\n",
              "      <td>[The Sun]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-16-014286</td>\n",
              "      <td>I don't want to make a career out of [ remakin...</td>\n",
              "      <td>Ramiro Gomez</td>\n",
              "      <td>[Q30693403, Q43130877]</td>\n",
              "      <td>2020-02-16 15:00:32</td>\n",
              "      <td>1</td>\n",
              "      <td>[https://www.theguardian.com/artanddesign/2020...</td>\n",
              "      <td>[The Guardian]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             quoteID  ...      newspapers\n",
              "0  2020-01-31-008580  ...  [The Guardian]\n",
              "1  2020-01-20-006469  ...       [The Sun]\n",
              "2  2020-04-03-006933  ...     [The Times]\n",
              "3  2020-04-15-018814  ...       [The Sun]\n",
              "4  2020-02-16-014286  ...  [The Guardian]\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WifW8YvwlTKW"
      },
      "source": [
        "Let's check that there are no 'None' speakers nore there is 'NaN' newspapers :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqYFW8r4lSRe",
        "outputId": "07ac3afc-a722-4281-af48-81b5fd1b8ba5"
      },
      "source": [
        "filtered_sample_df[filtered_sample_df.speaker=='None'].empty"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z63PUD6lrO4",
        "outputId": "4fa755c9-186d-4396-bba9-3f6b18471559"
      },
      "source": [
        "filtered_sample_df[filtered_sample_df.newspapers=='NaN'].empty"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLMg_0cfl6pg"
      },
      "source": [
        "Now let us do this filtering for the remaining data of years 2015-2019."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "AePNLWxAl6Vz",
        "outputId": "131d62a8-8380-4f64-ddf5-645b6a09d5b2"
      },
      "source": [
        "filter_data(RAW_QUOTES_2019_PATH,QUOTES_2019_PATH)\n",
        "filter_data(RAW_QUOTES_2018_PATH,QUOTES_2018_PATH)\n",
        "filter_data(RAW_QUOTES_2017_PATH,QUOTES_2017_PATH)\n",
        "filter_data(RAW_QUOTES_2016_PATH,QUOTES_2016_PATH)\n",
        "filter_data(RAW_QUOTES_2015_PATH,QUOTES_2015_PATH)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b65cb0d2c045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_QUOTES_2019_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUOTES_2019_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_QUOTES_2018_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUOTES_2018_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_QUOTES_2017_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUOTES_2017_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_QUOTES_2016_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUOTES_2016_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfilter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_QUOTES_2015_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUOTES_2015_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-5ad67bd581d4>\u001b[0m in \u001b[0;36mfilter_data\u001b[0;34m(path_in, path_out)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m               \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# loading a sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speaker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bz2.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/_compression.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE3n5IX4M0qY"
      },
      "source": [
        "### 2.4 Merge speaker informations\n",
        "<a id=\"merge_speaker_infos\"></a>\n",
        "**Lorena**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6_TmZzcl4rz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TiD-JUPl5Od"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh9eaDhyM0qY"
      },
      "source": [
        "## 3 Data exploration and cleaning\n",
        "<a id=\"data_explore_clean\"></a>\n",
        "**Marie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz1MVvi7M0qY"
      },
      "source": [
        "### 3.1 Import prepared data\n",
        "<a id=\"import_prep_data\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYNJ-AqbM0qZ"
      },
      "source": [
        "### 3.2 Set the index\n",
        "<a id=\"set_index\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeMRPw8YM0qZ",
        "outputId": "f907a3bd-3e3a-40b9-9fb1-207ca339878b"
      },
      "source": [
        "# The index is now unique\n",
        "df.index.is_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhCpq9plM0qZ"
      },
      "source": [
        "### 3.3 Save cleaned data frame as pickle\n",
        "<a id=\"save_pickle\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8O0LkrcM0qZ"
      },
      "source": [
        "## 4 Research questions\n",
        "<a id=\"research_questions\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L3aW7ndM0qZ"
      },
      "source": [
        "### 4.1 Load pickled dataframes\n",
        "<a id=\"load_pickle\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWicDUncM0qZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}